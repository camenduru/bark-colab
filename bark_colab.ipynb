{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/bark-colab/blob/main/bark_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/spaces/suno/bark/blob/main/app.py modified\n",
        "!pip install -q git+https://github.com/suno-ai/bark.git\n",
        "!pip install -q --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118\n",
        "!pip install -q gradio==3.27.0\n",
        "\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from bark import SAMPLE_RATE, generate_audio, preload_models\n",
        "from bark.generation import SUPPORTED_LANGS\n",
        "\n",
        "DEBUG_MODE = False\n",
        "\n",
        "if not DEBUG_MODE:\n",
        "    _ = preload_models()\n",
        "\n",
        "AVAILABLE_PROMPTS = [\"Unconditional\", \"Announcer\"]\n",
        "PROMPT_LOOKUP = {}\n",
        "for _, lang in SUPPORTED_LANGS:\n",
        "    for n in range(10):\n",
        "        label = f\"Speaker {n} ({lang})\"\n",
        "        AVAILABLE_PROMPTS.append(label)\n",
        "        PROMPT_LOOKUP[label] = f\"{lang}_speaker_{n}\"\n",
        "PROMPT_LOOKUP[\"Unconditional\"] = None\n",
        "PROMPT_LOOKUP[\"Announcer\"] = \"announcer\"\n",
        "\n",
        "default_text = \"Hello, my name is Suno. And, uh — and I like pizza. [laughs]\\nBut I also have other interests such as playing tic tac toe.\"\n",
        "\n",
        "def gen_tts(text, history_prompt, temp_semantic, temp_waveform):\n",
        "    history_prompt = PROMPT_LOOKUP[history_prompt]\n",
        "    if DEBUG_MODE:\n",
        "        audio_arr = np.zeros(SAMPLE_RATE)\n",
        "    else:\n",
        "        audio_arr = generate_audio(text, history_prompt=history_prompt, text_temp=temp_semantic, waveform_temp=temp_waveform)\n",
        "    audio_arr = (audio_arr * 32767).astype(np.int16)\n",
        "    return (SAMPLE_RATE, audio_arr)\n",
        "\n",
        "block = gr.Blocks()#.queue()\n",
        "with block:\n",
        "  text = gr.Textbox(label=\"Input Text\", lines=2, value=default_text)\n",
        "  history_prompt = gr.Dropdown(AVAILABLE_PROMPTS, value=\"Speaker 1 (en)\", label=\"Acoustic Prompt\")\n",
        "  temp_semantic = gr.Slider(minimum=0, maximum=1, step=0.01, value=0.7, label=\"Temp 1\", info=\"Gen. temperature of semantic tokens. (lower is more conservative, higher is more diverse)\")\n",
        "  temp_waveform = gr.Slider(minimum=0, maximum=1, step=0.01, value=0.7, label=\"Temp 2\", info=\"Gen. temperature of waveform tokens. (lower is more conservative, higher is more diverse)\")\n",
        "  result_audio = gr.Audio(label=\"Generated Audio\", type=\"numpy\")\n",
        "  run_button = gr.Button(label=\"Run\")\n",
        "  run_button.click(fn=gen_tts, inputs=[text, history_prompt, temp_semantic, temp_waveform], outputs=[result_audio])\n",
        "  examples = gr.Examples(examples=[\n",
        "    [\"Please surprise me and speak in whatever voice you enjoy. Vielen Dank und Gesundheit!\", \"Unconditional\"],#, 0.7, 0.7],\n",
        "    [\"Hello, my name is Suno. And, uh — and I like pizza. [laughs] But I also have other interests such as playing tic tac toe.\", \"Speaker 1 (en)\"],#, 0.7, 0.7],\n",
        "    [\"Buenos días Miguel. Tu colega piensa que tu alemán es extremadamente malo. But I suppose your english isn't terrible.\",  \"Speaker 0 (es)\"],#, 0.7, 0.7],\n",
        "    ], fn=gen_tts, inputs=[text, history_prompt, temp_semantic, temp_waveform], outputs=[result_audio], cache_examples=False)\n",
        "\n",
        "block.launch(debug=True, share=False, inline=True, height=950)"
      ],
      "metadata": {
        "id": "ngr4pZeHCM1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}