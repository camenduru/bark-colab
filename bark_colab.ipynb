{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/bark-colab/blob/main/bark_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngr4pZeHCM1C"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/spaces/suno/bark/blob/main/app.py modified\n",
        "!pip install -q git+https://github.com/camenduru/bark.git\n",
        "!pip install -q --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118\n",
        "!pip install -q gradio==3.27.0\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/bark_v0/resolve/main/6285677e88715abde42a9924db939b3b.pt -d /root/.cache/suno/bark_v0 -o 6285677e88715abde42a9924db939b3b.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/bark_v0/resolve/main/751d4d3d562e63ead5311ebe2a5f45a8.pt -d /root/.cache/suno/bark_v0 -o 751d4d3d562e63ead5311ebe2a5f45a8.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/bark_v0/resolve/main/e32937063d7ccececc61b2d2a3bb0a13.pt -d /root/.cache/suno/bark_v0 -o e32937063d7ccececc61b2d2a3bb0a13.pt\n",
        "\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from bark import SAMPLE_RATE, generate_audio, preload_models\n",
        "from bark.generation import SUPPORTED_LANGS\n",
        "\n",
        "_ = preload_models()\n",
        "\n",
        "AVAILABLE_PROMPTS = [\"Unconditional\", \"Announcer\"]\n",
        "PROMPT_LOOKUP = {}\n",
        "for _, lang in SUPPORTED_LANGS:\n",
        "    for n in range(10):\n",
        "        label = f\"Speaker {n} ({lang})\"\n",
        "        AVAILABLE_PROMPTS.append(label)\n",
        "        PROMPT_LOOKUP[label] = f\"{lang}_speaker_{n}\"\n",
        "PROMPT_LOOKUP[\"Unconditional\"] = None\n",
        "PROMPT_LOOKUP[\"Announcer\"] = \"announcer\"\n",
        "\n",
        "default_text = \"Hello, my name is Suno. And, uh — and I like pizza. [laughs]\\nBut I also have other interests such as playing tic tac toe.\"\n",
        "\n",
        "def gen_tts(text, history_prompt, temp_semantic, temp_waveform):\n",
        "    history_prompt = PROMPT_LOOKUP[history_prompt]\n",
        "    audio_arr = generate_audio(text, history_prompt=history_prompt, text_temp=temp_semantic, waveform_temp=temp_waveform)\n",
        "    audio_arr = (audio_arr * 32767).astype(np.int16)\n",
        "    return (SAMPLE_RATE, audio_arr)\n",
        "\n",
        "block = gr.Blocks()\n",
        "with block:\n",
        "  text = gr.Textbox(label=\"Input Text\", lines=2, value=default_text)\n",
        "  history_prompt = gr.Dropdown(AVAILABLE_PROMPTS, value=\"Speaker 1 (en)\", label=\"Acoustic Prompt\")\n",
        "  temp_semantic = gr.Slider(minimum=0, maximum=1, step=0.01, value=0.7, label=\"Temp 1\", info=\"Gen. temperature of semantic tokens. (lower is more conservative, higher is more diverse)\")\n",
        "  temp_waveform = gr.Slider(minimum=0, maximum=1, step=0.01, value=0.7, label=\"Temp 2\", info=\"Gen. temperature of waveform tokens. (lower is more conservative, higher is more diverse)\")\n",
        "  result_audio = gr.Audio(label=\"Generated Audio\", type=\"numpy\")\n",
        "  run_button = gr.Button(label=\"Run\")\n",
        "  run_button.click(fn=gen_tts, inputs=[text, history_prompt, temp_semantic, temp_waveform], outputs=[result_audio])\n",
        "  examples = gr.Examples(examples=[\n",
        "    [\"Please surprise me and speak in whatever voice you enjoy. Vielen Dank und Gesundheit!\", \"Unconditional\"],#, 0.7, 0.7],\n",
        "    [\"Hello, my name is Suno. And, uh — and I like pizza. [laughs] But I also have other interests such as playing tic tac toe.\", \"Speaker 1 (en)\"],#, 0.7, 0.7],\n",
        "    [\"Buenos días Miguel. Tu colega piensa que tu alemán es extremadamente malo. But I suppose your english isn't terrible.\",  \"Speaker 0 (es)\"],#, 0.7, 0.7],\n",
        "    ], fn=gen_tts, inputs=[text, history_prompt, temp_semantic, temp_waveform], outputs=[result_audio], cache_examples=False)\n",
        "\n",
        "block.launch(debug=True, share=False, inline=True, height=950)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
